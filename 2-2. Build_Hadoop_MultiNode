##########################
#   server01 에서..
##########################

//-- 다운로드

//모든 타사 응용 프로그램을이 /opt에 설치
cd /opt/src
wget https://dlcdn.apache.org/hadoop/common/hadoop-3.3.2/hadoop-3.3.2.tar.gz --no-check-certificate

//tar xfz : gzip으로 압축 해제 + tar 풀기
tar xfz hadoop-3.3.2.tar.gz

//hadoop-3.3.2를 한단계 위 디렉터리로 옮기기(/opt/src의 한단계 위 디렉터리이므로 /opt로 옮긴다는 말)
//mv는 파일이나 디렉터리의 이름을 바꿀 때도 사용
mv hadoop-3.3.2 ../
//한단계 위 디렉터리 즉 /opt로 간다는 말
cd ..
//hadoop-3.3.2를 hadoop이라는 이름으로 심볼릭링크(바로가기)를 만듬(앞으로 hadoop이라고 쓰면 hadoop-3.3.2를 의미함)
ln -s hadoop-3.3.2/ hadoop

//export : shell변수를 환경변수로 저장
// /etc/profile 모든 계정에 공통적으로 적용되는 환경설정을 저장
vi /etc/profile
-------------------------------------------------------------------
export HADOOP_HOME=/opt/hadoop
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
export HDFS_NAMENODE_USER="root"
export HDFS_DATANODE_USER="root"
export HDFS_SECONDARYNAMENODE_USER="root"
export YARN_RESOURCEMANAGER_USER="root"
export YARN_NODEMANAGER_USER="root"
----------------------------------------------------------------------

//source :스크립트파일을 수정한 후에 수정된 값을 바로 적용하기 위해 사용하는 명령어(스크립트파일은 수정해도 바로 적용되는 것이 아니라 리눅스를 재시작시 적용됨)
[root@server01 opt]# source /etc/profile
[root@server01 opt]# hadoop version
Hadoop 3.3.2
Source code repository git@github.com:apache/hadoop.git -r 0bcb014209e219273cb6fd4152df7df713cbac61
Compiled by chao on 2022-02-21T18:39Z
Compiled with protoc 3.7.1
From source with checksum 4b40fff8bb27201ba07b6fa5651217fb
This command was run using /opt/hadoop-3.3.2/share/hadoop/common/hadoop-common-3.3.2.jar

 vi $HADOOP_HOME/etc/hadoop/hadoop-env.sh
-------------------------------------------------------------------
55번째 줄..
export JAVA_HOME=/usr/java/jdk1.8

253번째줄
export HADOOP_SECURE_PID_DIR=/opt/hadoop/pids
-------------------------------------------------------------------

vi $HADOOP_HOME/etc/hadoop/core-site.xml
-------------------------------------------------------------------
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
        <property>
                <name>fs.defaultFS</name>
                <value>hdfs://server01:9000</value>
        </property>
</configuration>
-------------------------------------------------------------------


vi $HADOOP_HOME/etc/hadoop/hdfs-site.xml
-------------------------------------------------------------------
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
<property>
        <name>dfs.replication</name>
        <value>1</value>
</property>
<property>
        <name>dfs.permissions</name>
        <value>false</value>
</property>
<property>
        <name>dfs.namenode.name.dir</name>
        <value>file:/opt/hadoop/namenode</value>
</property>
<property>
        <name>dfs.datanode.data.dir</name>
        <value>file:/opt/hadoop/datanode</value>
</property>
</configuration>
-------------------------------------------------------------------

// 디렉토리 생성
//rm은 파일은 삭제할 수 디렉터리는 삭제할 수 없음(디렉터리와 내용을 모두 삭제하려면 rm -r, 삭제 확인 질문이 뜨지 않게 하려면 rm -rf)
//리눅스에서는 삭제된 파일이나 디렉터리를 복구할 수 없으므로 삭제시 매우 조심!
rm -rf $HADOOP_HOME/namenode
mkdir $HADOOP_HOME/namenode
chown root -R $HADOOP_HOME/namenode
chmod 777 $HADOOP_HOME/namenode

rm -rf $HADOOP_HOME/datanode
mkdir $HADOOP_HOME/datanode
chown root -R $HADOOP_HOME/datanode
chmod 777 $HADOOP_HOME/datanode




vi $HADOOP_HOME/etc/hadoop/mapred-site.xml
-------------------------------------------------------------------
<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
<property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
</property>

</configuration>
-------------------------------------------------------------------

vi $HADOOP_HOME/etc/hadoop/yarn-site.xml
-------------------------------------------------------------------
<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
<property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
</property>
<property>
        <name>yarn.nodemanager.auxservices.mapreduce.shuffle.class</name>
        <value>org.apache.hadoop.mapred.ShuffleHandler</value>
</property>
<property>
        <name>yarn.nodemanager.vmem-check-enabled</name>
        <value>false</value>
</property>
<property>
        <name>yarn.application.classpath</name>
       <value>/opt/hadoop/share/hadoop/mapreduce/*,/opt/hadoop/share/hadoop/mapreduce/lib/*,/opt/hadoop/share/hadoop/common/*,/opt/hadoop/share/hadoop/common/lib/*,/opt/hadoop/share/hadoop/hdfs/*,/opt/hadoop/share/hadoop/hdfs/lib/*,/opt/hadoop/share/hadoop/yarn/*,/opt/hadoop/share/hadoop/yarn/lib/*</value>
</property>
</configuration>
-------------------------------------------------------------------


master, worker ( server01에서만)
vi $HADOOP_HOME/etc/hadoop/masters
---------------------------------
server01
-----------------------------------

vi $HADOOP_HOME/etc/hadoop/workers
---------------------------------
server01
server02
server03
-----------------------------------


// 기존 정보 삭제...
rm -rf /tmp/hadoop*
rm -rf /opt/hadoop/logs/*

// 처음.. 한번만......(namenode를 초기화)
hdfs namenode -format

//namenode, datanode, nodemanager, secondarynamenode, yarn 데몬을 실행
start-all.sh

//테스트('hdfs dfs'가 앞에 붙은 것은 hadoop안에서 실행되는 명령어라는 의미)
hdfs dfs -mkdir /user
hdfs dfs -mkdir /user/root
hdfs dfs -mkdir /user/root/conf

hdfs dfs -mkdir /input

hdfs dfs -copyFromLocal /opt/hadoop/README.txt /input

hdfs dfs -ls /input

hadoop jar /opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.2.jar wordcount /input/README.txt ~/wordcount-output

hdfs dfs -ls ~/wordcount-output
